%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}~\label{chap:intro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Opening overview
Several technology constraints are threatening to slow the rate of
growth in computer system performance. Specifically, current designers
are finding difficulties addressing strict processor power consumption
and cooling constraints.  Design modifications to address power
consumption generally limit processor performance and reduce peak
operating frequency, thus changing the trend of providing increased
system performance every new processor generation.  As such, modern
architectures have diverged from the clock speed race into the
multi-core era with multiple processing cores on a single die. While
the multi-core design strategy improves chip power density, there
remains a significant potential in improving run-time power
utilization by dynamically changing per-core clock frequency and
voltage.

% WHAT IS DVFS
Power consumption has been observed to be 
directly proportional to the clock speed (frequency) and the 
square of the operating voltage of the processor 
($Power \propto frequency \times Voltage^2$). In order to conserve energy, designers have explored methods to
manipulate these parameters at runtime.
Implementations of DVFS schemes divides the processor operation in islands called 
performance states or P-states with fixed operating voltage and clock speeds. 
Architectures supporting DVFS mechanisms provide 2-8 such islands or DVFS configurations thus transforming
decisions in linear space to that in discrete space. 

Literature provides various schemes of manipulating DVFS configurations of a processor and
can be subdivided into three broad categories: hardware, operating system and compiler/runtime systems. 
DVFS at the architecture level, implemented 
in hardware to monitor and predict execution patterns and allowing the power optimizer
to react to such events to manipulate the system's DVFS configuration. These methods are 
presented and studied in \cite{SystemLevel}, \cite{Phaseaware} and \cite{ImprovingFairness}.
In-hardware methods are immutable implementations in silicon which cannot be changed based on
design and policy variations and hence avoided by many chip manufacturers who in turn rely on software for policy 
implementation and changes. Next 
\cite{MultiOptimization}, \cite{LiveRuntime}, \cite{OperatingSystem} and \cite{schedulerHPC} elevate these design 
considerations from the hardware to the operating system level which expect some form
of runtime performance monitoring capabilities exported from the hardware in order to measure 
and predict execution phase patterns to assist such operating system based power management systems.
Finally, the last category is the management of power controlled by compiler and user space runtime systems
which expect such capabilities to be exported by the operating system as discussed in \cite{dynamic_compiler_f},
\cite{AnIntraTask}, \cite{compilerDirectedDVFS} and trace driven methods for power management as discussed
in \cite{adagio} and \cite{boundingEnergy}.
 

Majority of DVFS (Dynamic Voltage and Frequency Scaling) implementations at the operating system level are load based where
the system's DVFS configuration is varied based upon the usage patters of the hardware. Even though
effective in conserving power, this methodology is unaware of the workload currently executing on
the system. Load based decisions
are best left to technologies which decide whether the processing element 
is active or asleep (The state at which the power consumption is minimal) and is studied in
\cite{OperatingSystem} which predicts usage patterns of various devices on the system. 

% Statement of work overview
This work proposes techniques which tie the scheduler and the system power optimizer to
constrain the number of DVFS level changes both over time and
intensity with the goal of  energy savings without harming
performance. Limiting DVFS level transitions becomes important to limit the instabilities endured by the system due to rapid
DVFS transitions as explored by \cite{ImpactDVFS}.

% Contributions
This thesis makes the following contributions to this area of study:
\begin{enumerate}
\item Method of scheduling to adjust DVFS with
strict constraints on limiting the amount of performance lost compared
to full frequency mode. The system provides significant power savings of up to 40\% 
with a performance loss of up to 20\% with a median performance loss at around 10-15\%.
\item Method to schedule tasks based on their performance requirement on a multi processor
environment with varying asymmetric clock speeds in order to maximize power savings
while minimizing performance lost. 
\item Investigation of the impact of DVFS level changes per second on the ability to improve power savings
or performance impact.
\item Devised a multi-task scheduling model that accounts for joule-per-instruction work metric.
\end{enumerate}

% Chapter Organization

This thesis is organized as follows:
Chapter~\ref{chap:pds} introduces the performance directed scheduler.
Chapter~\ref{chap:delta} proposes a methodology to mutate voltage and 
frequency configuration of a system based on the workload demands. 
Chapter~\ref{chap:results} describes the experimental procedure
and results obtained. Chapter~\ref{chap:future} comments on the future
work in this area and finally chapter~\ref{chap:conclusion} concludes this
thesis.   

